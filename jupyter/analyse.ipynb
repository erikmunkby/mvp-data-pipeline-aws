{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files from the bucket\n",
    "**NOTE:** No steps will work here unless you've set the AWS credentials in the poetry shell: \n",
    "- `export AWS_PROFILE=<your profile name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('my-mvp-pipeline-bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the file keys (each file is a batched output from the kinesis firehose)\n",
    "file_keys = [obj.key for obj in bucket.objects.filter(Prefix='events/')]\n",
    "# Print the first 5 in the list\n",
    "file_keys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a selected file into memory\n",
    "\n",
    "# Create the file as an object\n",
    "file = s3.Object(bucket.name, file_keys[0])\n",
    "# Read (download) the object\n",
    "json_line = file.get()['Body'].read().decode().strip()\n",
    "# In the pipeline .put_record() method we added a \\n so that we now can split on it to seperate the events\n",
    "json_list = [json.loads(x) for x in json_line.split('\\n')]\n",
    "# Print the first two events\n",
    "json_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the Jsons into a dataframe so we can work with them\n",
    "df = pd.json_normalize(json_list, sep='_')\n",
    "# Convert timestamp to humanly readable format\n",
    "df.loc[:, 'utc_timestamp'] = pd.to_datetime(df.utc_timestamp, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with dates\n",
    "Even better is to work with dates so you don't load everything at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_dates = set([datetime.strptime('-'.join(f.split('/')[1:4]), '%Y-%m-%d').date() for f in file_keys])\n",
    "print('Available dates:', available_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load specific file based on path\n",
    "def load_file(file_path):\n",
    "    file = s3.Object(bucket.name, file_path)\n",
    "    return file.get()['Body'].read().decode().strip()\n",
    "\n",
    "# Function to load everything existing under a specific date folder\n",
    "def load_date(date_str: str) -> list:\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "    date_path = '/'.join(str(date).split('-'))\n",
    "    filter_str = f'events/{date_path}/'\n",
    "    file_keys = [obj.key for obj in bucket.objects.filter(Prefix=filter_str)]\n",
    "    json_list = []\n",
    "    for f in file_keys:\n",
    "        json_list.extend([json.loads(x) for x in load_file(f).split('\\n')])\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific date (string converted into date object in function)\n",
    "jl = load_date('2020-10-29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(jl, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
